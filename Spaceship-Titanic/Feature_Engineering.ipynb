{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering on Spaceship Titanic Data\n",
    "This notebook focuses on transforming and creating new features from the raw Spaceship Titanic dataset to enhance model performance. \n",
    "It includes:\n",
    "- Extraction of meaningful features from columns such as `PassengerId`, `Cabin`, and `Age`.\n",
    "- Handling missing values using appropriate strategies for categorical and numerical features.\n",
    "- Feature normalization and transformation.\n",
    "- Target encoding for categorical features.\n",
    "- Final data preparation for machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "submission_data = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['Transported']\n",
    "x_train = train_data.drop(columns='Transported')\n",
    "\n",
    "y_test = submission_data['Transported']\n",
    "x_test = test_data\n",
    "\n",
    "\n",
    "x_data = pd.concat([x_train, x_test], axis=0, ignore_index=True)\n",
    "y_data = pd.concat([y_train, y_test], axis=0, ignore_index=True)\n",
    "\n",
    "train_test_data = pd.concat([x_data, y_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck             Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0  Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0     Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0    Altark Susent   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Features\n",
    "- Created `Group_Number` by extracting the prefix from `PassengerId`.\n",
    "- Calculated `Group_Size` by counting the occurrences of each `Group_Number` and mapped it accordingly.\n",
    "- Converted both `Group_Number` and `Group_Size` to float type.\n",
    "- Split the `Cabin` column into three new features: `Cabin_Deck`, `Cabin_Num`, and `Cabin_Side`.\n",
    "- Dropped the `PassengerId`, `Cabin`, and `Name` columns as they are not necessary for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data['Group_Number'] = train_test_data['PassengerId'].str.split('_').str[0]\n",
    "\n",
    "group_sizes = train_test_data['Group_Number'].value_counts()\n",
    "train_test_data['Group_Size'] = train_test_data['Group_Number'].map(group_sizes)\n",
    "\n",
    "train_test_data[['Group_Number', 'Group_Size']] = train_test_data[['Group_Number', 'Group_Size']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data[['Cabin_Deck', 'Cabin_Num', 'Cabin_Side']] = train_test_data['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "train_test_data['Cabin_Num'] = train_test_data['Cabin_Num'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_data[['FirstName', 'SureName']] = train_test_data['Name'].str.split(' ', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data.drop(columns=['PassengerId', 'Cabin', 'Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "- Checked and displayed the columns with missing values.\n",
    "- Filled missing categorical values with the mode of the respective feature.\n",
    "- Filled missing numerical values with the median of the respective feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet      288\n",
      "CryoSleep       310\n",
      "Destination     274\n",
      "Age             270\n",
      "VIP             296\n",
      "RoomService     263\n",
      "FoodCourt       289\n",
      "ShoppingMall    306\n",
      "Spa             284\n",
      "VRDeck          268\n",
      "Cabin_Deck      299\n",
      "Cabin_Num       299\n",
      "Cabin_Side      299\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = train_test_data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train_test_data.columns:\n",
    "    if train_test_data[feature].isnull().sum() > 0: \n",
    "        if (train_test_data[feature].dtype == 'object') or (train_test_data[feature].nunique() <= 10):\n",
    "            # Fill categorical missing values with mode\n",
    "            train_test_data[feature] = train_test_data[feature].fillna(train_test_data[feature].mode()[0])\n",
    "        else:\n",
    "            # Fill numerical missing values with median\n",
    "            train_test_data[feature] = train_test_data[feature].fillna(train_test_data[feature].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet      0\n",
       "CryoSleep       0\n",
       "Destination     0\n",
       "Age             0\n",
       "VIP             0\n",
       "RoomService     0\n",
       "FoodCourt       0\n",
       "ShoppingMall    0\n",
       "Spa             0\n",
       "VRDeck          0\n",
       "Transported     0\n",
       "Group_Number    0\n",
       "Group_Size      0\n",
       "Cabin_Deck      0\n",
       "Cabin_Num       0\n",
       "Cabin_Side      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating New Features\n",
    "- Created `Total_Spend` by summing the expenditures across different services.\n",
    "- Created `Has_Spent` as a boolean feature indicating whether the individual has spent any money.\n",
    "- Categorized individuals into age groups using the `Age` feature, resulting in the `Age_Group` feature.\n",
    "- Categorized individuals into cabin regions based on `Cabin_Num`, resulting in the `Cabin_Region` feature.\n",
    "- Converted `Age_Group` and `Cabin_Region` to categorical data type (`object`).\n",
    "- Dropped the original `Age` and `Cabin_Num` columns as they were no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data['Total_Spend'] = train_test_data['RoomService'] + train_test_data['FoodCourt'] + train_test_data['ShoppingMall'] + train_test_data['Spa'] + train_test_data['VRDeck']\n",
    "\n",
    "train_test_data['Has_Spent'] = train_test_data['Total_Spend'].apply(lambda x: True if x > 0 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 10, 16, 20, 26, 50, float('inf')]\n",
    "labels = ['Child', 'Young','Adult', 'Middle-Age', 'Senior', 'Old']\n",
    "\n",
    "train_test_data['Age_Group'] = pd.cut(train_test_data['Age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 300, 800, 1100, 1550, float('inf')]\n",
    "labels = ['r1', 'r2', 'r3', 'r4', 'r5']\n",
    "\n",
    "train_test_data['Cabin_Region'] = pd.cut(train_test_data['Cabin_Num'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data[['Age_Group', 'Cabin_Region']] = train_test_data[['Age_Group', 'Cabin_Region']].astype('object')\n",
    "train_test_data.drop(columns=['Age', 'Cabin_Num'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization & Transformation\n",
    "- Normalized the expenditure features relative to `Total_Spend`.\n",
    "- Applied log1p transformation to numerical features with high skewness to improve distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_normalize = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "for feature in feature_to_normalize:\n",
    "    train_test_data[feature] = train_test_data.apply(\n",
    "        lambda row: 0 if row['Total_Spend'] == 0 else row[feature] / row['Total_Spend'],\n",
    "        axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying log1p to: RoomService, Skewness: 2.14\n",
      "Applying log1p to: FoodCourt, Skewness: 2.15\n",
      "Applying log1p to: ShoppingMall, Skewness: 2.48\n",
      "Applying log1p to: Spa, Skewness: 2.41\n",
      "Applying log1p to: VRDeck, Skewness: 2.51\n",
      "Applying log1p to: Total_Spend, Skewness: 4.55\n"
     ]
    }
   ],
   "source": [
    "numerical_features = train_test_data.select_dtypes(include=['float64', 'int64']).columns[\n",
    "    train_test_data.select_dtypes(include=['float64', 'int64']).nunique() > 10\n",
    "]\n",
    "\n",
    "for feature in numerical_features:\n",
    "    skewness = train_test_data[feature].skew() \n",
    "    if abs(skewness) > 0.5: \n",
    "        print(f\"Applying log1p to: {feature}, Skewness: {skewness:.2f}\")\n",
    "        train_test_data[feature] = np.log1p(train_test_data[feature])  # log1p transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Encoding\n",
    "- Applied target encoding to categorical features with fewer than 10 unique values.\n",
    "- Mapped each category in these features to a value based on the survival rate of `Transported`.\n",
    "- Converted the entire dataset to float type after encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Group_Number</th>\n",
       "      <th>Group_Size</th>\n",
       "      <th>Cabin_Deck</th>\n",
       "      <th>Cabin_Side</th>\n",
       "      <th>Total_Spend</th>\n",
       "      <th>Has_Spent</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>Cabin_Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>Senior</td>\n",
       "      <td>r1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>False</td>\n",
       "      <td>0.138107</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.033403</td>\n",
       "      <td>0.557284</td>\n",
       "      <td>0.058064</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>6.602588</td>\n",
       "      <td>True</td>\n",
       "      <td>Middle-Age</td>\n",
       "      <td>r1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.295955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498792</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>9.248021</td>\n",
       "      <td>True</td>\n",
       "      <td>Old</td>\n",
       "      <td>r1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet  CryoSleep  Destination    VIP  RoomService  FoodCourt  \\\n",
       "0     Europa      False  TRAPPIST-1e  False     0.000000   0.000000   \n",
       "1      Earth      False  TRAPPIST-1e  False     0.138107   0.012154   \n",
       "2     Europa      False  TRAPPIST-1e   True     0.004133   0.295955   \n",
       "\n",
       "   ShoppingMall       Spa    VRDeck  Transported  Group_Number  Group_Size  \\\n",
       "0      0.000000  0.000000  0.000000        False           1.0         1.0   \n",
       "1      0.033403  0.557284  0.058064         True           2.0         1.0   \n",
       "2      0.000000  0.498792  0.004708        False           3.0         2.0   \n",
       "\n",
       "  Cabin_Deck Cabin_Side  Total_Spend  Has_Spent   Age_Group Cabin_Region  \n",
       "0          B          P     0.000000      False      Senior           r1  \n",
       "1          F          S     6.602588       True  Middle-Age           r1  \n",
       "2          A          S     9.248021       True         Old           r1  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_test_data.columns:\n",
    "    if train_test_data[column].nunique() <= 10: \n",
    "        # Calculate survival rates for each category in the column\n",
    "        survival_rates = train_test_data.groupby(column)['Transported'].mean()\n",
    "\n",
    "        # Sort the categories based on survival rates (ascending order)\n",
    "        survival_rates = survival_rates.sort_values()\n",
    "\n",
    "        # Create a mapping from category to survival rate-based values (0, 1, 2,...)\n",
    "        category_mapping = {category: idx for idx, category in enumerate(survival_rates.index)}\n",
    "\n",
    "        # Map the categories to their new values\n",
    "        train_test_data[column] = train_test_data[column].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = train_test_data.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Features\n",
    "- Applied StandardScaler to scale all numerical features to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_columns = train_test_data.columns\n",
    "\n",
    "train_test_data[numerical_columns] = scaler.fit_transform(train_test_data[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Saved Data for Modeling\n",
    "- Dropped the `Transported` column from `train_test_data` to separate features from the target variable.\n",
    "- Split the dataset into training (`train_x`, `train_y`) and testing (`test_x`, `test_y`) sets:\n",
    "  - `train_x`: Features for training.\n",
    "  - `test_x`: Features for testing.\n",
    "  - `train_y`: Target variable for training.\n",
    "  - `test_y`: Target variable for testing (from `submission_data`).\n",
    "- Saved `train_x`, `test_x`, `train_y`, and `test_y` as CSV files: `train_x.csv`, `test_x.csv`, `train_y.csv`, and `test_y.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data.drop(columns='Transported', inplace=True)\n",
    "\n",
    "train_x = train_test_data.iloc[:y_train.shape[0], :]\n",
    "test_x = train_test_data.iloc[y_train.shape[0]:, :]\n",
    "\n",
    "test_y = submission_data['Transported']\n",
    "train_y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 17), (8693,), (4277, 17), (4277,))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, y_train.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting datasets to CSV\n",
    "train_x.to_csv('train_x.csv', index=False)\n",
    "test_x.to_csv('test_x.csv', index=False)\n",
    "train_y.to_csv('train_y.csv', index=False)\n",
    "test_y.to_csv('test_y.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
